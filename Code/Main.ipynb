{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierre Nikitits\n",
    "## Course Project: Electricity Price Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "\n",
    "- Consumption\n",
    "- Exchange\n",
    "- Net Export/Import\n",
    "- Energy Sources\n",
    "- Residual Load\n",
    "- Weather Conditions\n",
    "- Market Dynamics\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Preprocessing Data\n",
    "2. Metric definition\n",
    "3. Define models: Random Forest, Linear Regression, SVR\n",
    "4. Hyperparameter Tuning: Grid Search\n",
    "5. Evaluation\n",
    "6. Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/Users/pierre/Documents/GitHub/EnsembleLearningProject/Data/\"\n",
    "\n",
    "X_train = pd.read_csv(path + 'X_train.csv').set_index('ID')\n",
    "y_train = pd.read_csv(path + 'y_train.csv').set_index('ID')\n",
    "X_test = pd.read_csv(path + 'X_test.csv').set_index('ID')\n",
    "y_test = pd.read_csv(path + 'y_test.csv').set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (1494, 34)\n",
      "y_train : (1494, 1)\n",
      "\n",
      "X_test  : (654, 34)\n",
      "y_test  : (654, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train :\" , X_train.shape)\n",
    "print(\"y_train :\" , y_train.shape)\n",
    "\n",
    "print(\"\\nX_test  :\" , X_test.shape)\n",
    "print(\"y_test  :\" , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['COUNTRY' , 'DAY_ID'], inplace=True)\n",
    "X_test.drop(columns=['COUNTRY' , 'DAY_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DE_CONSUMPTION</th>\n",
       "      <th>FR_CONSUMPTION</th>\n",
       "      <th>DE_FR_EXCHANGE</th>\n",
       "      <th>FR_DE_EXCHANGE</th>\n",
       "      <th>DE_NET_EXPORT</th>\n",
       "      <th>FR_NET_EXPORT</th>\n",
       "      <th>DE_NET_IMPORT</th>\n",
       "      <th>FR_NET_IMPORT</th>\n",
       "      <th>DE_GAS</th>\n",
       "      <th>FR_GAS</th>\n",
       "      <th>...</th>\n",
       "      <th>FR_RESIDUAL_LOAD</th>\n",
       "      <th>DE_RAIN</th>\n",
       "      <th>FR_RAIN</th>\n",
       "      <th>DE_WIND</th>\n",
       "      <th>FR_WIND</th>\n",
       "      <th>DE_TEMP</th>\n",
       "      <th>FR_TEMP</th>\n",
       "      <th>GAS_RET</th>\n",
       "      <th>COAL_RET</th>\n",
       "      <th>CARBON_RET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>0.210099</td>\n",
       "      <td>-0.427458</td>\n",
       "      <td>-0.606523</td>\n",
       "      <td>0.606523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.692860</td>\n",
       "      <td>0.441238</td>\n",
       "      <td>-0.213766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444661</td>\n",
       "      <td>-0.172680</td>\n",
       "      <td>-0.556356</td>\n",
       "      <td>-0.790823</td>\n",
       "      <td>-0.283160</td>\n",
       "      <td>-1.069070</td>\n",
       "      <td>-0.063404</td>\n",
       "      <td>0.339041</td>\n",
       "      <td>0.124552</td>\n",
       "      <td>-0.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>-0.022399</td>\n",
       "      <td>-1.003452</td>\n",
       "      <td>-0.022063</td>\n",
       "      <td>0.022063</td>\n",
       "      <td>-0.573520</td>\n",
       "      <td>-1.130838</td>\n",
       "      <td>0.573520</td>\n",
       "      <td>1.130838</td>\n",
       "      <td>0.174773</td>\n",
       "      <td>0.426940</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.183194</td>\n",
       "      <td>-1.240300</td>\n",
       "      <td>-0.770457</td>\n",
       "      <td>1.522331</td>\n",
       "      <td>0.828412</td>\n",
       "      <td>0.437419</td>\n",
       "      <td>1.831241</td>\n",
       "      <td>-0.659091</td>\n",
       "      <td>0.047114</td>\n",
       "      <td>-0.490365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>1.395035</td>\n",
       "      <td>1.978665</td>\n",
       "      <td>1.021305</td>\n",
       "      <td>-1.021305</td>\n",
       "      <td>-0.622021</td>\n",
       "      <td>-1.682587</td>\n",
       "      <td>0.622021</td>\n",
       "      <td>1.682587</td>\n",
       "      <td>2.351913</td>\n",
       "      <td>2.122241</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947273</td>\n",
       "      <td>-0.480700</td>\n",
       "      <td>-0.313338</td>\n",
       "      <td>0.431134</td>\n",
       "      <td>0.487608</td>\n",
       "      <td>0.684884</td>\n",
       "      <td>0.114836</td>\n",
       "      <td>0.535974</td>\n",
       "      <td>0.743338</td>\n",
       "      <td>0.204952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.983324</td>\n",
       "      <td>-0.849198</td>\n",
       "      <td>-0.839586</td>\n",
       "      <td>0.839586</td>\n",
       "      <td>-0.270870</td>\n",
       "      <td>0.563230</td>\n",
       "      <td>0.270870</td>\n",
       "      <td>-0.563230</td>\n",
       "      <td>0.487818</td>\n",
       "      <td>0.194659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.976974</td>\n",
       "      <td>-1.114838</td>\n",
       "      <td>-0.507570</td>\n",
       "      <td>-0.499409</td>\n",
       "      <td>-0.236249</td>\n",
       "      <td>0.350938</td>\n",
       "      <td>-0.417514</td>\n",
       "      <td>0.911652</td>\n",
       "      <td>-0.296168</td>\n",
       "      <td>1.073948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>0.143807</td>\n",
       "      <td>-0.617038</td>\n",
       "      <td>-0.924990</td>\n",
       "      <td>0.924990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.990324</td>\n",
       "      <td>0.238693</td>\n",
       "      <td>-0.240862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526267</td>\n",
       "      <td>-0.541465</td>\n",
       "      <td>-0.424550</td>\n",
       "      <td>-1.088158</td>\n",
       "      <td>-1.011560</td>\n",
       "      <td>0.614338</td>\n",
       "      <td>0.729495</td>\n",
       "      <td>0.245109</td>\n",
       "      <td>1.526606</td>\n",
       "      <td>2.614378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DE_CONSUMPTION  FR_CONSUMPTION  DE_FR_EXCHANGE  FR_DE_EXCHANGE  \\\n",
       "ID                                                                     \n",
       "1054        0.210099       -0.427458       -0.606523        0.606523   \n",
       "2049       -0.022399       -1.003452       -0.022063        0.022063   \n",
       "1924        1.395035        1.978665        1.021305       -1.021305   \n",
       "297        -0.983324       -0.849198       -0.839586        0.839586   \n",
       "1101        0.143807       -0.617038       -0.924990        0.924990   \n",
       "\n",
       "      DE_NET_EXPORT  FR_NET_EXPORT  DE_NET_IMPORT  FR_NET_IMPORT    DE_GAS  \\\n",
       "ID                                                                           \n",
       "1054            NaN       0.692860            NaN      -0.692860  0.441238   \n",
       "2049      -0.573520      -1.130838       0.573520       1.130838  0.174773   \n",
       "1924      -0.622021      -1.682587       0.622021       1.682587  2.351913   \n",
       "297       -0.270870       0.563230       0.270870      -0.563230  0.487818   \n",
       "1101            NaN       0.990324            NaN      -0.990324  0.238693   \n",
       "\n",
       "        FR_GAS  ...  FR_RESIDUAL_LOAD   DE_RAIN   FR_RAIN   DE_WIND   FR_WIND  \\\n",
       "ID              ...                                                             \n",
       "1054 -0.213766  ...         -0.444661 -0.172680 -0.556356 -0.790823 -0.283160   \n",
       "2049  0.426940  ...         -1.183194 -1.240300 -0.770457  1.522331  0.828412   \n",
       "1924  2.122241  ...          1.947273 -0.480700 -0.313338  0.431134  0.487608   \n",
       "297   0.194659  ...         -0.976974 -1.114838 -0.507570 -0.499409 -0.236249   \n",
       "1101 -0.240862  ...         -0.526267 -0.541465 -0.424550 -1.088158 -1.011560   \n",
       "\n",
       "       DE_TEMP   FR_TEMP   GAS_RET  COAL_RET  CARBON_RET  \n",
       "ID                                                        \n",
       "1054 -1.069070 -0.063404  0.339041  0.124552   -0.002445  \n",
       "2049  0.437419  1.831241 -0.659091  0.047114   -0.490365  \n",
       "1924  0.684884  0.114836  0.535974  0.743338    0.204952  \n",
       "297   0.350938 -0.417514  0.911652 -0.296168    1.073948  \n",
       "1101  0.614338  0.729495  0.245109  1.526606    2.614378  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.dropna()\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test.loc[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 32)\n",
      "(1276, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "- Mean Squared Error\n",
    "- Root Mean Squared Error\n",
    "- Mean Absolute Error\n",
    "- R-squared\n",
    "- Mean Absolute Percentage Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score , mean_absolute_percentage_error , log_loss\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "def find_metrics(y_test_values , predicted_values):\n",
    "    mse = mean_squared_error(y_test_values, predicted_values)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "    rmse = sqrt(mean_squared_error(y_test_values, predicted_values))\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "    mae = mean_absolute_error(y_test_values, predicted_values)\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "    r2 = r2_score(y_test_values, predicted_values)\n",
    "    print(f\"R-squared (RÂ²): {r2}\")\n",
    "\n",
    "    mape = mean_absolute_percentage_error(y_test_values, predicted_values)\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n",
    "\n",
    "    # loss1 = log_loss(y_test_values , predicted_values)\n",
    "    # print(f\"log loss: {loss1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Definitions\n",
    "\n",
    "1. Random Forest\n",
    "2. Linear Regression\n",
    "3. SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m random_forest \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     11\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mrandom_forest, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel())\n\u001b[1;32m     14\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [600],\n",
    "#     'max_depth': [2, 3, 4],\n",
    "#     'min_samples_split': [8 , 9, 10]\n",
    "# }\n",
    "\n",
    "# random_forest = RandomForestRegressor(random_state=42)\n",
    "# grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best Parameters:\", best_params)\n",
    "# print(\"Best Score:\" , grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-03 18:44:49,615] A new study created in RDB with name: example_study_with_pruning\n",
      "[I 2024-03-03 18:44:56,573] Trial 2 finished with value: 2.530427168518719 and parameters: {'n_estimators': 440, 'max_depth': 3, 'min_samples_split': 6}. Best is trial 2 with value: 2.530427168518719.\n",
      "[I 2024-03-03 18:44:58,784] Trial 7 finished with value: 3.505404953539682 and parameters: {'n_estimators': 265, 'max_depth': 7, 'min_samples_split': 11}. Best is trial 2 with value: 2.530427168518719.\n",
      "[I 2024-03-03 18:45:07,668] Trial 9 finished with value: 3.559016381989093 and parameters: {'n_estimators': 288, 'max_depth': 7, 'min_samples_split': 7}. Best is trial 2 with value: 2.530427168518719.\n",
      "[I 2024-03-03 18:45:08,569] Trial 6 finished with value: 4.057221747037212 and parameters: {'n_estimators': 518, 'max_depth': 8, 'min_samples_split': 7}. Best is trial 2 with value: 2.530427168518719.\n",
      "[I 2024-03-03 18:45:10,622] Trial 1 finished with value: 4.4016724692326035 and parameters: {'n_estimators': 449, 'max_depth': 11, 'min_samples_split': 10}. Best is trial 2 with value: 2.530427168518719.\n",
      "[I 2024-03-03 18:45:16,201] Trial 3 finished with value: 3.5290577134053183 and parameters: {'n_estimators': 950, 'max_depth': 6, 'min_samples_split': 7}. Best is trial 2 with value: 2.530427168518719.\n",
      "[I 2024-03-03 18:45:17,815] Trial 5 pruned. \n",
      "[I 2024-03-03 18:45:21,080] Trial 10 finished with value: 2.965145999795185 and parameters: {'n_estimators': 689, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 2 with value: 2.530427168518719.\n",
      "[I 2024-03-03 18:45:24,304] Trial 8 pruned. \n",
      "[I 2024-03-03 18:45:31,232] Trial 0 pruned. \n",
      "[I 2024-03-03 18:45:32,738] Trial 16 pruned. \n",
      "[I 2024-03-03 18:45:32,817] Trial 13 finished with value: 3.302945975033491 and parameters: {'n_estimators': 685, 'max_depth': 5, 'min_samples_split': 6}. Best is trial 2 with value: 2.530427168518719.\n",
      "[I 2024-03-03 18:45:35,662] Trial 4 pruned. \n",
      "[I 2024-03-03 18:45:35,960] Trial 17 finished with value: 2.380505037304149 and parameters: {'n_estimators': 404, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 17 with value: 2.380505037304149.\n",
      "[I 2024-03-03 18:45:37,167] Trial 12 pruned. \n",
      "[I 2024-03-03 18:45:37,670] Trial 18 finished with value: 2.404034120801246 and parameters: {'n_estimators': 416, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 17 with value: 2.380505037304149.\n",
      "[I 2024-03-03 18:45:38,159] Trial 19 finished with value: 2.3998120255449544 and parameters: {'n_estimators': 441, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 17 with value: 2.380505037304149.\n",
      "[I 2024-03-03 18:45:41,021] Trial 21 finished with value: 2.40519026922609 and parameters: {'n_estimators': 415, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 17 with value: 2.380505037304149.\n",
      "[I 2024-03-03 18:45:41,740] Trial 20 finished with value: 2.3887374965194415 and parameters: {'n_estimators': 489, 'max_depth': 2, 'min_samples_split': 9}. Best is trial 17 with value: 2.380505037304149.\n",
      "[I 2024-03-03 18:45:42,320] Trial 11 pruned. \n",
      "[I 2024-03-03 18:45:42,479] Trial 22 finished with value: 2.3821253971405034 and parameters: {'n_estimators': 406, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 17 with value: 2.380505037304149.\n",
      "[I 2024-03-03 18:45:42,980] Trial 23 finished with value: 2.385474615561248 and parameters: {'n_estimators': 387, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 17 with value: 2.380505037304149.\n",
      "[I 2024-03-03 18:45:43,077] Trial 15 pruned. \n",
      "[I 2024-03-03 18:45:45,249] Trial 24 finished with value: 2.3772393984784097 and parameters: {'n_estimators': 551, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 24 with value: 2.3772393984784097.\n",
      "[I 2024-03-03 18:45:49,795] Trial 29 pruned. \n",
      "[I 2024-03-03 18:45:49,844] Trial 30 pruned. \n",
      "[I 2024-03-03 18:45:50,359] Trial 14 pruned. \n",
      "[I 2024-03-03 18:45:51,809] Trial 31 pruned. \n",
      "[I 2024-03-03 18:45:53,057] Trial 25 pruned. \n",
      "[I 2024-03-03 18:45:53,424] Trial 26 pruned. \n",
      "[I 2024-03-03 18:45:53,809] Trial 27 pruned. \n",
      "[I 2024-03-03 18:45:54,357] Trial 28 pruned. \n",
      "[I 2024-03-03 18:45:58,609] Trial 33 pruned. \n",
      "[I 2024-03-03 18:45:58,632] Trial 32 pruned. \n",
      "[I 2024-03-03 18:45:59,360] Trial 38 pruned. \n",
      "[I 2024-03-03 18:45:59,455] Trial 34 pruned. \n",
      "[I 2024-03-03 18:46:00,242] Trial 39 pruned. \n",
      "[I 2024-03-03 18:46:00,783] Trial 35 pruned. \n",
      "[I 2024-03-03 18:46:01,456] Trial 36 pruned. \n",
      "[I 2024-03-03 18:46:01,507] Trial 37 pruned. \n",
      "[I 2024-03-03 18:46:04,956] Trial 47 finished with value: 2.3886249532889687 and parameters: {'n_estimators': 279, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 24 with value: 2.3772393984784097.\n",
      "[I 2024-03-03 18:46:05,162] Trial 40 pruned. \n",
      "[I 2024-03-03 18:46:05,695] Trial 43 finished with value: 2.3886245359235727 and parameters: {'n_estimators': 490, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 24 with value: 2.3772393984784097.\n",
      "[I 2024-03-03 18:46:05,829] Trial 41 pruned. \n",
      "[I 2024-03-03 18:46:05,861] Trial 42 finished with value: 2.3794467835573605 and parameters: {'n_estimators': 495, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 24 with value: 2.3772393984784097.\n",
      "[I 2024-03-03 18:46:06,973] Trial 44 finished with value: 2.375657339456136 and parameters: {'n_estimators': 502, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 44 with value: 2.375657339456136.\n",
      "[I 2024-03-03 18:46:07,421] Trial 45 finished with value: 2.395943598101146 and parameters: {'n_estimators': 473, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 44 with value: 2.375657339456136.\n",
      "[I 2024-03-03 18:46:08,156] Trial 46 finished with value: 2.398409173412851 and parameters: {'n_estimators': 477, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 44 with value: 2.375657339456136.\n",
      "[I 2024-03-03 18:46:09,456] Trial 49 finished with value: 2.388403950753895 and parameters: {'n_estimators': 244, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 44 with value: 2.375657339456136.\n",
      "[I 2024-03-03 18:46:09,864] Trial 48 finished with value: 2.397286306306864 and parameters: {'n_estimators': 268, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 44 with value: 2.375657339456136.\n",
      "[I 2024-03-03 18:46:19,029] Trial 50 pruned. \n",
      "[I 2024-03-03 18:46:19,480] Trial 52 pruned. \n",
      "[I 2024-03-03 18:46:19,845] Trial 53 pruned. \n",
      "[I 2024-03-03 18:46:20,371] Trial 55 pruned. \n",
      "[I 2024-03-03 18:46:23,504] Trial 51 pruned. \n",
      "[I 2024-03-03 18:46:24,512] Trial 54 pruned. \n",
      "[I 2024-03-03 18:46:24,922] Trial 60 pruned. \n",
      "[I 2024-03-03 18:46:26,687] Trial 57 pruned. \n",
      "[I 2024-03-03 18:46:27,188] Trial 59 finished with value: 2.3828617491279025 and parameters: {'n_estimators': 634, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 44 with value: 2.375657339456136.\n",
      "[I 2024-03-03 18:46:27,654] Trial 62 finished with value: 2.3595264963854303 and parameters: {'n_estimators': 309, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 62 with value: 2.3595264963854303.\n",
      "[I 2024-03-03 18:46:28,295] Trial 61 finished with value: 2.3880754749234563 and parameters: {'n_estimators': 642, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 62 with value: 2.3595264963854303.\n",
      "[I 2024-03-03 18:46:29,332] Trial 56 pruned. \n",
      "[I 2024-03-03 18:46:30,462] Trial 58 pruned. \n",
      "[I 2024-03-03 18:46:31,033] Trial 65 finished with value: 2.3585732177888326 and parameters: {'n_estimators': 313, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 65 with value: 2.3585732177888326.\n",
      "[I 2024-03-03 18:46:31,458] Trial 64 finished with value: 2.378286442938264 and parameters: {'n_estimators': 513, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 65 with value: 2.3585732177888326.\n",
      "[I 2024-03-03 18:46:33,301] Trial 69 finished with value: 2.3572708536169036 and parameters: {'n_estimators': 312, 'max_depth': 2, 'min_samples_split': 10}. Best is trial 69 with value: 2.3572708536169036.\n",
      "[I 2024-03-03 18:46:35,094] Trial 72 finished with value: 2.3671479642265094 and parameters: {'n_estimators': 306, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 69 with value: 2.3572708536169036.\n",
      "[I 2024-03-03 18:46:36,462] Trial 66 pruned. \n",
      "[I 2024-03-03 18:46:44,787] Trial 71 pruned. \n",
      "[I 2024-03-03 18:46:45,357] Trial 73 pruned. \n",
      "[I 2024-03-03 18:46:46,020] Trial 63 pruned. \n",
      "[I 2024-03-03 18:46:47,367] Trial 74 pruned. \n",
      "[I 2024-03-03 18:46:48,715] Trial 78 finished with value: 2.3884844309300983 and parameters: {'n_estimators': 209, 'max_depth': 2, 'min_samples_split': 10}. Best is trial 69 with value: 2.3572708536169036.\n",
      "[I 2024-03-03 18:46:49,086] Trial 76 pruned. \n",
      "[I 2024-03-03 18:46:49,523] Trial 75 pruned. \n",
      "[I 2024-03-03 18:46:49,601] Trial 77 pruned. \n",
      "[I 2024-03-03 18:46:50,230] Trial 79 finished with value: 2.384199723401207 and parameters: {'n_estimators': 202, 'max_depth': 2, 'min_samples_split': 10}. Best is trial 69 with value: 2.3572708536169036.\n",
      "[I 2024-03-03 18:46:52,072] Trial 80 pruned. \n",
      "[I 2024-03-03 18:46:53,336] Trial 81 finished with value: 2.3548131448398624 and parameters: {'n_estimators': 323, 'max_depth': 2, 'min_samples_split': 10}. Best is trial 81 with value: 2.3548131448398624.\n",
      "[I 2024-03-03 18:46:54,088] Trial 82 finished with value: 2.3575533193899645 and parameters: {'n_estimators': 353, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 81 with value: 2.3548131448398624.\n",
      "[I 2024-03-03 18:46:55,239] Trial 67 pruned. \n",
      "[I 2024-03-03 18:46:56,329] Trial 83 finished with value: 2.3735255524131897 and parameters: {'n_estimators': 538, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 81 with value: 2.3548131448398624.\n",
      "[I 2024-03-03 18:46:56,837] Trial 84 finished with value: 2.3730304310738015 and parameters: {'n_estimators': 540, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 81 with value: 2.3548131448398624.\n",
      "[I 2024-03-03 18:46:59,147] Trial 88 finished with value: 2.358531470978697 and parameters: {'n_estimators': 328, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 81 with value: 2.3548131448398624.\n",
      "[I 2024-03-03 18:46:59,506] Trial 86 pruned. \n",
      "[I 2024-03-03 18:46:59,990] Trial 68 pruned. \n",
      "[I 2024-03-03 18:47:00,321] Trial 87 pruned. \n",
      "[I 2024-03-03 18:47:02,000] Trial 89 pruned. \n",
      "[I 2024-03-03 18:47:02,061] Trial 70 pruned. \n",
      "[I 2024-03-03 18:47:02,718] Trial 90 pruned. \n",
      "[I 2024-03-03 18:47:02,742] Trial 85 finished with value: 2.3792602100246802 and parameters: {'n_estimators': 845, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 81 with value: 2.3548131448398624.\n",
      "[I 2024-03-03 18:47:04,507] Trial 94 finished with value: 2.357344853277451 and parameters: {'n_estimators': 318, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 81 with value: 2.3548131448398624.\n",
      "[I 2024-03-03 18:47:05,341] Trial 92 pruned. \n",
      "[I 2024-03-03 18:47:05,793] Trial 93 pruned. \n",
      "[I 2024-03-03 18:47:05,837] Trial 91 pruned. \n",
      "[I 2024-03-03 18:47:05,847] Trial 96 pruned. \n",
      "[I 2024-03-03 18:47:06,006] Trial 97 pruned. \n",
      "[I 2024-03-03 18:47:06,128] Trial 98 pruned. \n",
      "[I 2024-03-03 18:47:06,164] Trial 95 finished with value: 2.355923494214719 and parameters: {'n_estimators': 326, 'max_depth': 2, 'min_samples_split': 11}. Best is trial 81 with value: 2.3548131448398624.\n",
      "[I 2024-03-03 18:47:06,840] Trial 99 pruned. \n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape_error\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 200, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 11)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 4, 11)\n",
    "\n",
    "    \n",
    "    random_forest = RandomForestRegressor(\n",
    "        random_state=11,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split\n",
    "    )\n",
    "    \n",
    "    random_forest.fit(X_train, y_train.values.ravel())\n",
    "    pred = random_forest.predict(X_test)\n",
    "\n",
    "    \n",
    "    error = mape_error(y_test, pred)\n",
    "\n",
    "    trial.report(error, step=0)\n",
    "\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize',\n",
    "                            pruner=pruner,\n",
    "                            study_name=\"example_study_with_pruning\",\n",
    "                            storage='sqlite:///example_study_with_pruning.db',\n",
    "                            load_if_exists=True)\n",
    "\n",
    "study.optimize(objective, n_trials=100 , n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: FrozenTrial(number=81, state=1, values=[2.3548131448398624], datetime_start=datetime.datetime(2024, 3, 3, 18, 46, 49, 116179), datetime_complete=datetime.datetime(2024, 3, 3, 18, 46, 53, 293653), params={'n_estimators': 323, 'max_depth': 2, 'min_samples_split': 10}, user_attrs={}, system_attrs={}, intermediate_values={0: 2.3548131448398624}, distributions={'n_estimators': IntDistribution(high=1000, log=False, low=200, step=1), 'max_depth': IntDistribution(high=11, log=False, low=2, step=1), 'min_samples_split': IntDistribution(high=11, log=False, low=4, step=1)}, trial_id=82, value=None)\n",
      "Best parameters: {'n_estimators': 323, 'max_depth': 2, 'min_samples_split': 10}\n",
      "Best value (accuracy): 2.3548131448398624\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best trial: {study.best_trial}\")\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "print(f\"Best value (accuracy): {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.104491606844341\n",
      "Root Mean Squared Error (RMSE): 1.050947956296762\n",
      "Mean Absolute Error (MAE): 0.8460797895221016\n",
      "R-squared (RÂ²): -0.051758170734791165\n",
      "Mean Absolute Percentage Error (MAPE): 2.4003542132188103%\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(random_state=42 , n_estimators=323 , max_depth=2 , min_samples_split=10)\n",
    "random_forest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "random_forest_pred = random_forest.predict(X_test)\n",
    "find_metrics(y_test['TARGET'].values , random_forest_pred)\n",
    "\n",
    "\n",
    "# print(y_test['TARGET'].values.shape)\n",
    "# print(random_forest_pred.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "linear_pred = linear_regression.predict(X_test)\n",
    "find_metrics(y_test , linear_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid_svr = {\n",
    "#     'kernel': ['linear', 'rbf'],\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'gamma': ['scale', 'auto']\n",
    "# }\n",
    "\n",
    "# svr = SVR()\n",
    "\n",
    "# grid_search_svr = GridSearchCV(estimator=svr, param_grid=param_grid_svr, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# grid_search_svr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# best_params_svr = grid_search_svr.best_params_\n",
    "# print(\"Best Parameters for SVR:\", best_params_svr)\n",
    "# print(\"Best Score for SVR:\", grid_search_svr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(kernel='linear' , C=10 , gamma='scale')\n",
    "svr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "svr_pred = svr.predict(X_test)\n",
    "find_metrics(y_test , svr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "voting_ensemble = VotingRegressor([('rf', random_forest), ('lr', linear_regression), ('svr', svr)])\n",
    "voting_ensemble.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred_voting = voting_ensemble.predict(X_test)\n",
    "find_metrics(y_test , y_pred_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "stacking_ensemble = StackingRegressor([('rf', random_forest), ('lr', linear_regression), ('svr', svr)],\n",
    "                                      final_estimator=LinearRegression())\n",
    "stacking_ensemble.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred_stacking = stacking_ensemble.predict(X_test)\n",
    "find_metrics(y_test , y_pred_stacking)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
