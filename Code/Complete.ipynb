{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierre Nikitits\n",
    "## Course Project: Electricity Price Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "\n",
    "- Consumption\n",
    "- Exchange\n",
    "- Net Export/Import\n",
    "- Energy Sources\n",
    "- Residual Load\n",
    "- Weather Conditions\n",
    "- Market Dynamics\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Preprocessing Data\n",
    "2. Metric definition\n",
    "3. Define models: Random Forest, Linear Regression, SVR, XGboost\n",
    "4. Hyperparameter Tuning: Optuna search\n",
    "5. Evaluation\n",
    "6. Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/Users/pierre/Documents/GitHub/EnsembleLearningProject/Data/\"\n",
    "\n",
    "X_train = pd.read_csv(path + 'X_train.csv').set_index('ID')\n",
    "y_train = pd.read_csv(path + 'y_train.csv').set_index('ID')\n",
    "X_test = pd.read_csv(path + 'X_test.csv').set_index('ID')\n",
    "y_test = pd.read_csv(path + 'y_test.csv').set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train :\" , X_train.shape)\n",
    "print(\"y_train :\" , y_train.shape)\n",
    "\n",
    "print(\"\\nX_test  :\" , X_test.shape)\n",
    "print(\"y_test  :\" , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['COUNTRY' , 'DAY_ID'], inplace=True)\n",
    "X_test.drop(columns=['COUNTRY' , 'DAY_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.dropna()\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test.loc[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "- Mean Squared Error\n",
    "- Root Mean Squared Error\n",
    "- Mean Absolute Error\n",
    "- R-squared\n",
    "- Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score , mean_absolute_percentage_error , log_loss\n",
    "from math import sqrt\n",
    "\n",
    "def find_metrics(y_test_values , predicted_values):\n",
    "    mse = mean_squared_error(y_test_values, predicted_values)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "    rmse = sqrt(mean_squared_error(y_test_values, predicted_values))\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "    mae = mean_absolute_error(y_test_values, predicted_values)\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "    r2 = r2_score(y_test_values, predicted_values)\n",
    "    print(f\"R-squared (RÂ²): {r2}\")\n",
    "\n",
    "    mape = mean_absolute_percentage_error(y_test_values, predicted_values)\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Definitions\n",
    "\n",
    "1. Random Forest\n",
    "2. Linear Regression\n",
    "3. SVR\n",
    "4. XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape_error\n",
    "import logging\n",
    "logging.getLogger(\"optuna\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "def objective_rand_forest(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 200, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 11)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 4, 11)\n",
    "\n",
    "    \n",
    "    random_forest = RandomForestRegressor(\n",
    "        random_state=11,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split\n",
    "    )\n",
    "    \n",
    "    random_forest.fit(X_train, y_train.values.ravel())\n",
    "    pred = random_forest.predict(X_test)\n",
    "\n",
    "    \n",
    "    error = mape_error(y_test, pred)\n",
    "\n",
    "    trial.report(error, step=0)\n",
    "\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "\n",
    "\n",
    "study_rand_forest = optuna.create_study(direction='minimize',\n",
    "                            pruner=pruner,\n",
    "                            study_name=\"example_study_with_pruning\",\n",
    "                            storage='sqlite:///example_study_with_pruning.db',\n",
    "                            load_if_exists=True)\n",
    "\n",
    "study_rand_forest.optimize(objective_rand_forest, n_trials=100 , n_jobs=-1)\n",
    "\n",
    "print(f\"Best trial: {study_rand_forest.best_trial}\")\n",
    "print(f\"Best parameters: {study_rand_forest.best_params}\")\n",
    "print(f\"Best value (accuracy): {study_rand_forest.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestRegressor(random_state=42 , n_estimators=323 , max_depth=2 , min_samples_split=10)\n",
    "random_forest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "random_forest_pred = random_forest.predict(X_test)\n",
    "find_metrics(y_test['TARGET'].values , random_forest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "feature_importances = random_forest.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(len(feature_importances)), feature_importances[sorted_indices], align=\"center\")\n",
    "plt.xticks(range(len(feature_importances)), feature_names[sorted_indices], rotation=90)\n",
    "plt.xlim([-1, len(feature_importances)])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
